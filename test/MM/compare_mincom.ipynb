{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import chi2,f_classif,mutual_info_classif,mutual_info_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from parfor import parfor\n",
    "import time\n",
    "\n",
    "from parfor import parfor\n",
    "from scipy import io as sio\n",
    "from scipy import sparse as ss\n",
    "from scipy import optimize as so\n",
    "from sklearn.utils.sparsefuncs import mean_variance_axis\n",
    "from scipy.stats import linregress\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-belarus",
   "metadata": {},
   "source": [
    "## Six comparing Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_create(path, name, msg):\n",
    "    full_path = path + \"/\" + name + '.txt'\n",
    "    file = open(full_path, 'w')\n",
    "    file.write(str(msg))\n",
    "\n",
    "def SVM(X, y):\n",
    "    model = svm.LinearSVC(max_iter=1000000)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_error(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return mean_squared_error(y_pred, y)\n",
    "\n",
    "def feature_compare(path,X, Y, X_test,Y_test,num_features, num_samples):\n",
    "    train_error=[]\n",
    "    test_error=[]\n",
    "    train_acc=[]\n",
    "    test_acc=[]\n",
    "    D = np.shape(X)[1]\n",
    "    # Random\n",
    "    ran_idx = random.choices(range(D), k=num_features)\n",
    "    text_create(path,'ran_idx',ran_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,ran_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,ran_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,ran_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,ran_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,ran_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,ran_idx[:(i+1)]],Y_test))\n",
    "    print('ran_idx:')\n",
    "    print(ran_idx)\n",
    "    \n",
    "    # correlation coefficient \n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(f_classif, k=D).fit(X[indices[:num_samples]], Y[indices[:num_samples]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    cor_idx=[]\n",
    "    for i in range(num_features):\n",
    "        new_idx=[i for i in tmp[i] if i not in cor_idx][0]\n",
    "        cor_idx.append(new_idx)\n",
    "    text_create(path,'cor_idx',cor_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,cor_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,cor_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,cor_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,cor_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,cor_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,cor_idx[:(i+1)]],Y_test))\n",
    "    print('cor_idx:')\n",
    "    print(cor_idx)\n",
    "    \n",
    "    # mutual\n",
    "    #@parfor(range(num_features), bar=False)\n",
    "    #def tmp(i):\n",
    "    tmp=[]\n",
    "    for i in range(num_features):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(mutual_info_classif, k=D).fit(X[indices[:num_samples]], Y[indices[:num_samples]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        tmp.append([x for _, x in sorted(zip(score, idx), reverse=True)])\n",
    "        #return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    mut_idx=[]\n",
    "    for i in range(num_features):\n",
    "        new_idx=[i for i in tmp[i] if i not in mut_idx][0]\n",
    "        mut_idx.append(new_idx)\n",
    "    text_create(path,'mut_idx',mut_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,mut_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,mut_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,mut_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,mut_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,mut_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,mut_idx[:(i+1)]],Y_test))\n",
    "    print('mut_idx:')\n",
    "    print(mut_idx)\n",
    "    \n",
    "    # chi2\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(chi2, k=D).fit(X[indices[:num_samples]], Y[indices[:num_samples]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    chi_idx=[]\n",
    "    for i in range(num_features):\n",
    "        new_idx=[i for i in tmp[i] if i not in chi_idx][0]\n",
    "        chi_idx.append(new_idx)\n",
    "    text_create(path,'chi_idx',chi_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,chi_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,chi_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,chi_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,chi_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,chi_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,chi_idx[:(i+1)]],Y_test))\n",
    "    print('chi_idx:')\n",
    "    print(chi_idx)\n",
    "    \n",
    "    # Feature importance is an inbuilt class that comes with Tree Based Classifiers\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = ExtraTreesClassifier()\n",
    "        model.fit(X[indices[:num_samples]], Y[indices[:num_samples]])\n",
    "        coef = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in np.abs(model.feature_importances_)]\n",
    "        return sorted(range(len(coef)), key=lambda i: coef[i], reverse=True)\n",
    "    tree_idx=[]\n",
    "    for i in range(num_features):\n",
    "        new_idx=[i for i in tmp[i] if i not in tree_idx][0]\n",
    "        tree_idx.append(new_idx)\n",
    "    text_create(path,'tree_idx',tree_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,tree_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,tree_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,tree_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,tree_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,tree_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,tree_idx[:(i+1)]],Y_test))\n",
    "    print('tree_idx:')\n",
    "    print(tree_idx)\n",
    "    \n",
    "    # SVM by weight\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model=SVM(X[indices[:num_samples]], Y[indices[:num_samples]])\n",
    "        weight=np.sum(np.abs(model.coef_),axis=0).tolist()\n",
    "        coef = [0 if math.isnan(x) or x==float('inf') else x for x in weight]\n",
    "        return sorted(range(len(coef)), key=lambda i: coef[i], reverse=True)\n",
    "    svm_idx=[]\n",
    "    for i in range(num_features):\n",
    "        new_idx=[i for i in tmp[i] if i not in svm_idx][0]\n",
    "        svm_idx.append(new_idx)\n",
    "    text_create(path,'svm_idx',svm_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,svm_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,svm_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,svm_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,svm_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,svm_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,svm_idx[:(i+1)]],Y_test))\n",
    "    print('svm_idx:')\n",
    "    print(svm_idx)\n",
    "    text_create(path,'compare_train_error',train_error)\n",
    "    text_create(path,'compare_test_error',test_error)\n",
    "    text_create(path,'compare_train_acc',train_acc)\n",
    "    text_create(path,'compare_test_acc',test_acc)\n",
    "    return train_error,test_error,train_acc,test_acc,ran_idx,cor_idx,mut_idx,chi_idx,tree_idx,svm_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-print",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file='./data/MM_all_matrix.mtx'\n",
    "gene_file='./data/genes.tsv'\n",
    "label_file='./data/MM_all_metadata.csv'\n",
    "\n",
    "M, raw_gene, meta = load_consolidated_data(data_file, label_file, gene_file)\n",
    "M2, meta = normalization(M, meta)\n",
    "meta = pd.read_csv(label_file,header=0)\n",
    "\n",
    "l=[]\n",
    "for i in range(np.shape(raw_gene)[0]):\n",
    "    if raw_gene[i][:3]!='RPL' and raw_gene[i][:3]!='RPS' and raw_gene[i][:2]!='MT':\n",
    "        l.append(i)\n",
    "gene=raw_gene[l]\n",
    "\n",
    "data=normalize(M2.tocsr().transpose()[:,l],axis=1, norm='l2')\n",
    "\n",
    "raw_target=meta[\"disease\"].values\n",
    "target=(raw_target=='MM')*1.0\n",
    "target=target.astype(np.uint8)\n",
    "classes=range(len(np.unique(target)))\n",
    "keys=['healthy','MM']\n",
    "del M,M2,raw_gene,meta,raw_target\n",
    "\n",
    "idx = np.arange(np.shape(data)[0])\n",
    "random.shuffle(idx)\n",
    "X_train = data[idx[:int(np.shape(data)[0]*4/5)],:]\n",
    "y_train = target[idx[:int(np.shape(data)[0]*4/5)]]\n",
    "X_test = data[idx[int(np.shape(data)[0]*4/5):],:]\n",
    "y_test = target[idx[int(np.shape(data)[0]*4/5):]]\n",
    "\n",
    "print(type(data))\n",
    "print(np.shape(data),np.shape(target),len(np.unique(target)))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "for i in np.unique(target):\n",
    "    print('class '+keys[i]+': '+str(np.count_nonzero((target==i)*1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consolidated-profession",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Parameters\n",
    "----------\n",
    "balance : boolean\n",
    "    balance the number of cells of each class or just randomly select cells at each loop\n",
    "num_features : int\n",
    "    the total number of genes we want to select \n",
    "num_samples : int\n",
    "    the number of cells we would use at each loop\n",
    "'''\n",
    "\n",
    "num_features = 150\n",
    "num_samples=20\n",
    "\n",
    "path='results/compare_mincom'\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \")\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "train_error,test_error,train_acc,train_acc,ran_idx,fvalue_idx,mut_idx,chi_idx,tree_idx,svm_idx=feature_compare(path,X_train, y_train, X_test,y_test,num_features, num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convinced-journey",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
