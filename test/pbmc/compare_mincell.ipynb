{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-cartoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "from scipy.io import mmread\n",
    "import math\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cosine\n",
    "import os\n",
    "from matplotlib import gridspec\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, SelectFromModel\n",
    "from sklearn.feature_selection import chi2,f_classif,mutual_info_classif,mutual_info_regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from parfor import parfor\n",
    "import time\n",
    "from time import sleep\n",
    "from parfor import parfor\n",
    "from scipy import io as sio\n",
    "from scipy import sparse as ss\n",
    "from scipy import optimize as so\n",
    "from sklearn.utils.sparsefuncs import mean_variance_axis\n",
    "from scipy.stats import linregress\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import copy\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informative-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_create(path, name, msg):\n",
    "    full_path = path + \"/\" + name + '.txt'\n",
    "    file = open(full_path, 'w')\n",
    "    file.write(str(msg))\n",
    "\n",
    "def SVM(X, y):\n",
    "    model = svm.LinearSVC(max_iter=1000000)\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_error(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return mean_squared_error(y_pred, y)\n",
    "\n",
    "def feature_compare(path,X, Y, X_test,Y_test,num_features, num_samples_list):\n",
    "    train_error=[]\n",
    "    test_error=[]\n",
    "    train_acc=[]\n",
    "    test_acc=[]\n",
    "    D = np.shape(X)[1]\n",
    "    # Random\n",
    "    ran_idx = random.choices(range(D), k=num_features)\n",
    "    text_create(path,'ran_idx',ran_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,ran_idx[:(i+1)]],Y)\n",
    "        train_error.append(get_error(model,X[:,ran_idx[:(i+1)]],Y))\n",
    "        train_acc.append(model.score(X[:,ran_idx[:(i+1)]],Y))\n",
    "        model=SVM(X_test[:,ran_idx[:(i+1)]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,ran_idx[:(i+1)]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,ran_idx[:(i+1)]],Y_test))\n",
    "    print('ran_idx:')\n",
    "    print(ran_idx)\n",
    "    \n",
    "    # correlation coefficient \n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(f_classif, k=D).fit(X[indices[:num_samples_list[i]]], Y[indices[:num_samples_list[i]]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    cor_idx=[]\n",
    "    for i in range(num_features):\n",
    "        cor_idx.append(tmp[i][:(i+1)])\n",
    "    text_create(path,'cor_idx',cor_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,cor_idx[i]],Y)\n",
    "        train_error.append(get_error(model,X[:,cor_idx[i]],Y))\n",
    "        train_acc.append(model.score(X[:,cor_idx[i]],Y))\n",
    "        model=SVM(X_test[:,cor_idx[i]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,cor_idx[i]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,cor_idx[i]],Y_test))\n",
    "    print('cor_idx:')\n",
    "    print(cor_idx)\n",
    "    \n",
    "    # mutual\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(mutual_info_classif, k=D).fit(X[indices[:num_samples_list[i]]], Y[indices[:num_samples_list[i]]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    mut_idx=[]\n",
    "    for i in range(num_features):\n",
    "        mut_idx.append(tmp[i][:(i+1)])\n",
    "    text_create(path,'mut_idx',mut_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,mut_idx[i]],Y)\n",
    "        train_error.append(get_error(model,X[:,mut_idx[i]],Y))\n",
    "        train_acc.append(model.score(X[:,mut_idx[i]],Y))\n",
    "        model=SVM(X_test[:,mut_idx[i]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,mut_idx[i]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,mut_idx[i]],Y_test))\n",
    "    print('mut_idx:')\n",
    "    print(mut_idx)\n",
    "    \n",
    "    # chi2\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = SelectKBest(chi2, k=D).fit(X[indices[:num_samples_list[i]]], Y[indices[:num_samples_list[i]]])\n",
    "        score_raw = np.abs(model.scores_).tolist()\n",
    "        score = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in score_raw]\n",
    "        idx = model.get_support(indices=True).tolist()\n",
    "        return [x for _, x in sorted(zip(score, idx), reverse=True)]\n",
    "    chi_idx=[]\n",
    "    for i in range(num_features):\n",
    "        chi_idx.append(tmp[i][:(i+1)])\n",
    "    text_create(path,'chi_idx',chi_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,chi_idx[i]],Y)\n",
    "        train_error.append(get_error(model,X[:,chi_idx[i]],Y))\n",
    "        train_acc.append(model.score(X[:,chi_idx[i]],Y))\n",
    "        model=SVM(X_test[:,chi_idx[i]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,chi_idx[i]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,chi_idx[i]],Y_test))\n",
    "    print('chi_idx:')\n",
    "    print(chi_idx)\n",
    "    \n",
    "    # Feature importance is an inbuilt class that comes with Tree Based Classifiers\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model = ExtraTreesClassifier()\n",
    "        model.fit(X[indices[:num_samples_list[i]]], Y[indices[:num_samples_list[i]]])\n",
    "        coef = [float('-inf') if math.isnan(x) or x==float('inf') else x for x in np.abs(model.feature_importances_)]\n",
    "        return sorted(range(len(coef)), key=lambda i: coef[i], reverse=True)\n",
    "    tree_idx=[]\n",
    "    for i in range(num_features):\n",
    "        tree_idx.append(tmp[i][:(i+1)])\n",
    "    text_create(path,'tree_idx',tree_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,tree_idx[i]],Y)\n",
    "        train_error.append(get_error(model,X[:,tree_idx[i]],Y))\n",
    "        train_acc.append(model.score(X[:,tree_idx[i]],Y))\n",
    "        model=SVM(X_test[:,tree_idx[i]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,tree_idx[i]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,tree_idx[i]],Y_test))\n",
    "    print('tree_idx:')\n",
    "    print(tree_idx)\n",
    "    \n",
    "    # SVM by weight\n",
    "    @parfor(range(num_features), bar=False)\n",
    "    def tmp(i):\n",
    "        indices=np.arange(np.shape(X)[0])\n",
    "        random.shuffle(indices)\n",
    "        model=SVM(X[indices[:num_samples_list[i]]], Y[indices[:num_samples_list[i]]])\n",
    "        weight=np.sum(np.abs(model.coef_),axis=0).tolist()\n",
    "        coef = [0 if math.isnan(x) or x==float('inf') else x for x in weight]\n",
    "        return sorted(range(len(coef)), key=lambda i: coef[i], reverse=True)\n",
    "    svm_idx=[]\n",
    "    for i in range(num_features):\n",
    "        svm_idx.append(tmp[i][:(i+1)])\n",
    "    text_create(path,'svm_idx',svm_idx)\n",
    "    for i in range(num_features):\n",
    "        model=SVM(X[:,svm_idx[i]],Y)\n",
    "        train_error.append(get_error(model,X[:,svm_idx[i]],Y))\n",
    "        train_acc.append(model.score(X[:,svm_idx[i]],Y))\n",
    "        model=SVM(X_test[:,svm_idx[i]],Y_test)\n",
    "        test_error.append(get_error(model,X_test[:,svm_idx[i]],Y_test))\n",
    "        test_acc.append(model.score(X_test[:,svm_idx[i]],Y_test))\n",
    "    print('svm_idx:')\n",
    "    print(svm_idx)\n",
    "    text_create(path,'compare_train_error',train_error)\n",
    "    text_create(path,'compare_test_error',test_error)\n",
    "    text_create(path,'compare_train_acc',train_acc)\n",
    "    text_create(path,'compare_test_acc',test_acc)\n",
    "    return train_error,test_error,train_acc,test_acc,ran_idx,cor_idx,mut_idx,chi_idx,tree_idx,svm_idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amateur-sydney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(10194, 6915) (10194,) 5\n",
      "(8155, 6915)\n",
      "(2039, 6915)\n",
      "class Monocytes: 3269\n",
      "class T cells: 3517\n",
      "class Act. T/NK: 1265\n",
      "class B cells: 995\n",
      "class Others: 1148\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv('./data/PBMCnorm_final.csv')\n",
    "label_df=pd.read_csv('./data/labels_final.csv',header = None)\n",
    "gene_df=pd.read_csv('./data/genes_final.csv')\n",
    "classes=[0,1,2,3,4]\n",
    "keys=['Monocytes','T cells','Act. T/NK','B cells','Others']\n",
    "\n",
    "raw_data=data_df.values\n",
    "target=label_df.values.reshape((raw_data.shape[1],)).astype(np.uint8)-1\n",
    "gene=gene_df.values.reshape((raw_data.shape[0],))\n",
    "data=normalize(np.transpose(raw_data),axis=1, norm='l2')\n",
    "del data_df,label_df,gene_df,raw_data\n",
    "\n",
    "\n",
    "idx = np.arange(np.shape(data)[0])\n",
    "random.shuffle(idx)\n",
    "X_train = data[idx[:int(np.shape(data)[0]*4/5)],:]\n",
    "y_train = target[idx[:int(np.shape(data)[0]*4/5)]]\n",
    "X_test = data[idx[int(np.shape(data)[0]*4/5):],:]\n",
    "y_test = target[idx[int(np.shape(data)[0]*4/5):]]\n",
    "\n",
    "print(type(data))\n",
    "print(np.shape(data),np.shape(target),len(np.unique(target)))\n",
    "print(np.shape(X_train))\n",
    "print(np.shape(X_test))\n",
    "for i in np.unique(target):\n",
    "    print('class '+keys[i]+': '+str(np.count_nonzero((target==i)*1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "seven-plasma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creation of the directory %s failed\n",
      "Successfully created the directory results/compare_mincell \n",
      "ran_idx:\n",
      "[1195, 781, 2372, 715, 2344]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   0    3   12 ... 6905 6911 6913] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   0    1    3 ... 6912 6913 6914] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   0    3    8 ... 6911 6912 6913] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   0    3    4 ... 6903 6911 6913] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:114: UserWarning: Features [   0    1    3 ... 6911 6912 6913] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx,\n",
      "/Users/xqchen/opt/anaconda3/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:116: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cor_idx:\n",
      "[[3893], [1863, 2779], [2779, 5069, 1717], [4017, 3893, 4659, 2779], [3893, 2619, 3894, 5015, 3721]]\n",
      "mut_idx:\n",
      "[[2323], [430, 2025], [2323, 2230, 3758], [2025, 2230, 3893, 4376], [2230, 2323, 3893, 4376, 1097]]\n",
      "chi_idx:\n",
      "[[4719], [6118, 3721], [6203, 3721, 6118], [3721, 4718, 6118, 1717], [4719, 3721, 6203, 6118, 870]]\n",
      "tree_idx:\n",
      "[[6064], [6756, 5350], [3893, 979, 4488], [563, 488, 3895, 6118], [3702, 6203, 3893, 2779, 3895]]\n",
      "svm_idx:\n",
      "[[5475], [5475, 1829], [6203, 5475, 870], [6203, 870, 1829, 5475], [5475, 1829, 6203, 870, 1863]]\n"
     ]
    }
   ],
   "source": [
    "# You can ignore all warnings here\n",
    "num_features = 100\n",
    "num_samples_list=[200, 200, 212, 214, 245, 248, 249, 252, 261, 261, 275, 281, 281, 286, 286, 289, 291, 294, 298, 298, 301, 303, 305, 306, 306, 306, 306, 306, 306, 306, 306, 306, 306, 307, 307, 308, 308, 308, 308, 308, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 309, 312, 312, 312, 315, 316, 316, 318, 319, 319, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 320, 321, 321, 321, 321, 321, 321, 321, 322, 322, 322, 322, 322, 322]\n",
    "\n",
    "\n",
    "path='results/compare_mincell'\n",
    "try:\n",
    "    os.mkdir('results')\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\")\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \")\n",
    "try:\n",
    "    os.mkdir(path)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s \" % path)\n",
    "\n",
    "train_error,test_error,train_acc,train_acc,ran_idx,fvalue_idx,mut_idx,chi_idx,tree_idx,svm_idx=feature_compare(path,X_train, y_train, X_test,y_test,num_features, num_samples_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158f329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
